---
title: Scaling
description: How to configure Teleport for large-scale deployments
---

This section covers recommended configurations for large-scale
deployments of Teleport.

<Notice type="warning" scope={["cloud"]}>
For Teleport Cloud customers, the settings in this guide are configured automatically.
</Notice>

## Prerequisites

- Teleport v(=teleport.version=) Open Source or Enterprise.


## Hardware recommendations

Set up Teleport with a [High Availability configuration](../reference/backends.mdx).

| Scenario | Max Recommended Count | Proxy | Auth Server | AWS Instance Types |
| - | - | - | - | - |
| Teleport Nodes connected to Auth Service | 10,000 | 2x  4 vCPUs, 8GB RAM | 2x 8 vCPUs, 16GB RAM | m4.2xlarge |
| Teleport Nodes connected to Proxy Service through reverse tunnels | 10,000 | 2x 4 vCPUs, 8GB RAM | 2x 8 vCPUs, 16+GB RAM | m4.2xlarge |

## Auth and Proxy Configuration

Upgrade Teleport's connection limits from default connection limit of `15000` to
`65000`.

```yaml
# Teleport Auth and Proxy
teleport:
  connection_limits:
    max_connections: 65000
    max_users: 1000
```

## Kernel parameters

Tweak Teleport's systemd unit parameters to allow a higher amount of open files:

```txt
[Service]
LimitNOFILE=65536
```

Verify that Teleport's process has high enough file limits:

```code
$ cat /proc/$(pidof teleport)/limits
# Limit                     Soft Limit           Hard Limit           Units
# Max open files            65536                65536                files
```
